{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8989304,"sourceType":"datasetVersion","datasetId":5414130}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import Callback\nimport os\nimport random\nimport numpy as np\nimport keras\nfrom tqdm import tqdm\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport cv2  # Import OpenCV\n\n# Set seed for reproducibility\nseed = 40\n\n# Constants\nIMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 3\nTRAIN_PATH = '/kaggle/input/solar-rooftop-2d-unet-contours/archive/images/images'\nMASK_PATH = '/kaggle/input/solar-rooftop-2d-unet-contours/archive/label/label'  # Adjust the mask path\nTEST_PATH = '/kaggle/input/solar-rooftop-2d-unet-contours/archive/images/images'\n\n# Check if paths exist and are not empty\nassert os.path.exists(TRAIN_PATH), f\"Training path '{TRAIN_PATH}' does not exist.\"\nassert os.path.exists(TEST_PATH), f\"Testing path '{TEST_PATH}' does not exist.\"\nassert os.path.exists(MASK_PATH), f\"Mask path '{MASK_PATH}' does not exist.\"\n\n# Get train and test IDs\ntrain_ids = [file for file in os.listdir(TRAIN_PATH) if file.endswith('.tif')]\ntest_ids = [file for file in os.listdir(TEST_PATH) if file.endswith('.tif')]\n\nassert len(train_ids) > 0, f\"No training data found in '{TRAIN_PATH}'.\"\nassert len(test_ids) > 0, f\"No testing data found in '{TEST_PATH}'.\"\n\n# Initialize arrays for images and masks\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n\n# Preprocess training images and masks\nprint('Resizing training images and masks')\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    image_path = os.path.join(TRAIN_PATH, id_)\n    img = imread(image_path)[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img  # Fill empty X_train with values from img\n\n    mask_id = id_.replace('.tif', '_label.tif')\n    mask_path = os.path.join(MASK_PATH, mask_id)\n    mask = imread(mask_path, as_gray=True)\n    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n    Y_train[n] = mask\n\n# Preprocess test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Resizing test images')\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    image_path = os.path.join(TEST_PATH, id_)\n    img = imread(image_path)[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img\n\nprint('Done!')\n\n# Visualize a random training sample\nimage_x = random.randint(0, len(train_ids) - 1)\nimshow(X_train[image_x])\nplt.show()\nimshow(np.squeeze(Y_train[image_x]))\nplt.show()\n\n# Build the model\ninputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\ns = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n\n# Contraction path\nc1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\nc1 = tf.keras.layers.Dropout(0.1)(c1)\nc1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\np1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\nc2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\nc2 = tf.keras.layers.Dropout(0.1)(c2)\nc2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\np2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n\nc3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\nc3 = tf.keras.layers.Dropout(0.2)(c3)\nc3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\np3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n\nc4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\nc4 = tf.keras.layers.Dropout(0.2)(c4)\nc4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\np4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n\nc5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\nc5 = tf.keras.layers.Dropout(0.3)(c5)\nc5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n\n# Expansive path\nu6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\nu6 = tf.keras.layers.concatenate([u6, c4])\nc6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\nc6 = tf.keras.layers.Dropout(0.2)(c6)\nc6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n\nu7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\nu7 = tf.keras.layers.concatenate([u7, c3])\nc7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\nc7 = tf.keras.layers.Dropout(0.2)(c7)\nc7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n\nu8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\nu8 = tf.keras.layers.concatenate([u8, c2])\nc8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\nc8 = tf.keras.layers.Dropout(0.1)(c8)\nc8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n\nu9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\nu9 = tf.keras.layers.concatenate([u9, c1], axis=3)\nc9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\nc9 = tf.keras.layers.Dropout(0.1)(c9)\nc9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n\noutputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n\nmodel = tf.keras.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\nclass CustomEarlyStopping(Callback):\n    def __init__(self, threshold=0.99, patience=10):\n        super(CustomEarlyStopping, self).__init__()\n        self.threshold = threshold\n        self.patience = patience\n        self.best_weights = None\n        self.wait = 0\n        self.best_val_acc = -1  # Initialize best_val_acc attribute\n\n    def on_epoch_end(self, epoch, logs=None):\n        current_val_acc = logs.get('val_accuracy')\n        if current_val_acc >= self.threshold:\n            self.best_weights = self.model.get_weights()\n            self.model.stop_training = True\n        if self.best_weights is not None:\n            if current_val_acc <= self.best_val_acc:\n                self.wait += 1\n                if self.wait >= self.patience:\n                    self.model.stop_training = True\n                    self.model.set_weights(self.best_weights)\n            else:\n                self.best_val_acc = current_val_acc  # Update best_val_acc\n                self.wait = 0\n                self.best_weights = self.model.get_weights()\n\n# Model checkpoint to save the best model\ncheckpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.keras', verbose=1, save_best_only=True)\n\n# Include the custom callback\ncustom_early_stopping = CustomEarlyStopping()\n\ncallbacks = [\n    custom_early_stopping,\n    tf.keras.callbacks.TensorBoard(log_dir='logs')\n]\n\n# Train the model with the new callback\nresults = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=25, callbacks=[checkpointer, custom_early_stopping])\n\n# Load the best model\nmodel.load_weights('model_for_nuclei.keras')\n\n# Make predictions\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)\n\n# Function to draw polygons on the image\ndef draw_polygons(image, mask):\n    # Find contours\n    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    # Draw contours\n    cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n    \n    return image\n\n# Perform a sanity check on some random training samples\nfor _ in range(10):\n    ix = random.randint(0, len(preds_train_t) - 1)\n    \n    # Get the training image, true mask, and predicted mask\n    img = X_train[ix]\n    true_mask = np.squeeze(Y_train[ix])\n    pred_mask = np.squeeze(preds_train_t[ix])\n    \n    # Convert predicted mask to the right format for contour detection\n    pred_mask = (pred_mask * 255).astype(np.uint8)\n    \n    # Draw polygons on the predicted mask\n    img_with_polygons = draw_polygons(img.copy(), pred_mask)\n    \n    # Plot the images\n    plt.figure(figsize=(20, 6))\n    plt.subplot(1, 4, 1)\n    imshow(img)\n    plt.title('Training Image')\n    plt.subplot(1, 4, 2)\n    imshow(true_mask)\n    plt.title('True Mask')\n    plt.subplot(1, 4, 3)\n    imshow(pred_mask)\n    plt.title('Predicted Mask')\n    plt.subplot(1, 4, 4)\n    imshow(img_with_polygons)\n    plt.title('Image with Polygons')\n    plt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-19T08:02:05.336536Z","iopub.execute_input":"2024-07-19T08:02:05.337168Z","iopub.status.idle":"2024-07-19T08:34:57.839234Z","shell.execute_reply.started":"2024-07-19T08:02:05.337118Z","shell.execute_reply":"2024-07-19T08:34:57.837921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-19T07:57:08.725570Z","iopub.execute_input":"2024-07-19T07:57:08.726093Z","iopub.status.idle":"2024-07-19T07:57:08.739978Z","shell.execute_reply.started":"2024-07-19T07:57:08.726052Z","shell.execute_reply":"2024-07-19T07:57:08.738448Z"},"trusted":true},"execution_count":null,"outputs":[]}]}